{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "intro",
   "metadata": {},
   "source": [
    "# ðŸ“Š Visualize Metrics\n",
    "### ðŸ”— Ensure `BenchmarkLakehouse` is connected as a data source before running.\n",
    "\n",
    "This notebook compares performance and storage across different ingestion, update, and query strategies.\n",
    "\n",
    "Activities visualized:\n",
    "- Initial ingestion\n",
    "- Update\n",
    "- Query\n",
    "- Storage cost for each target\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "load_metrics",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load metrics table from Lakehouse (or local CSV for dev)\n",
    "try:\n",
    "    metrics_df = spark.read.table(\"BenchmarkLakehouse.metrics\").toPandas()\n",
    "except Exception:\n",
    "    import pandas as pd\n",
    "    metrics_df = pd.read_csv(\"metrics.csv\")\n",
    "metrics_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "id": "storage_calc",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate storage_size_mb if missing\n",
    "import math\n",
    "\n",
    "def calculate_storage_for_table(table_path):\n",
    "    try:\n",
    "        import mssparkutils\n",
    "        files = mssparkutils.fs.ls(table_path)\n",
    "        size_mb = sum(f.size for f in files) / (1024 * 1024)\n",
    "        return size_mb\n",
    "    except Exception:\n",
    "        return float('nan')\n",
    "\n",
    "# Identify unique targets and fill missing storage_size_mb\n",
    "for idx, row in metrics_df.iterrows():\n",
    "    if ('storage_size_mb' in row and (pd.isna(row['storage_size_mb']) or math.isnan(row['storage_size_mb']))) and row['update_strategy']:\n",
    "        # crude extraction: use test_case_id to guess table name (customize if needed)\n",
    "        tc = row['test_case_id']\n",
    "        # Mapping for demo, real code should use actual table names\n",
    "        table_map = {\n",
    "            'TC.01.x': '/lakehouse/BenchmarkLakehouse/Tables/delta_refresh_load',\n",
    "            'TC.02.x': '/lakehouse/BenchmarkLakehouse/Tables/wh_table_refresh_load',\n",
    "            'TC.03.x': '/lakehouse/BenchmarkLakehouse/Tables/delta_refresh_load',\n",
    "            'TC.04.x': '/lakehouse/BenchmarkLakehouse/Tables/wh_table_refresh_load',\n",
    "            'TC.05.x': '/lakehouse/BenchmarkLakehouse/Tables/delta_compare_load',\n",
    "            'TC.06.x': '/lakehouse/BenchmarkLakehouse/Tables/wh_table_compare_load',\n",
    "            'TC.07.x': '/lakehouse/BenchmarkLakehouse/Tables/delta_increment_load',\n",
    "            'TC.08.x': '/lakehouse/BenchmarkLakehouse/Tables/wh_table_increment_load',\n",
    "        }\n",
    "        table_path = table_map.get(tc, None)\n",
    "        if table_path:\n",
    "            metrics_df.at[idx, 'storage_size_mb'] = calculate_storage_for_table(table_path)"
   ]
  },
  {
   "cell_type": "code",
   "id": "ingest_vis",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Initial ingestion performance\n",
    "import matplotlib.pyplot as plt\n",
    "ingest_df = metrics_df[metrics_df['update_strategy'] == 'Full Refresh']\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.bar(ingest_df['format'], ingest_df['ingest_time_s'], color=['skyblue', 'orange'])\n",
    "plt.title(\"Initial Ingestion Time by Format\")\n",
    "plt.xlabel(\"Format\")\n",
    "plt.ylabel(\"Ingestion Time (s)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "id": "update_vis",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Update performance comparison\n",
    "update_df = metrics_df[metrics_df['update_strategy'].isin(['Full Compare', 'Incremental'])]\n",
    "plt.figure(figsize=(8,4))\n",
    "for strategy in update_df['update_strategy'].unique():\n",
    "    strat_df = update_df[update_df['update_strategy'] == strategy]\n",
    "    plt.bar(strat_df['format'] + \" \" + strat_df['update_strategy'], strat_df['ingest_time_s'], label=strategy)\n",
    "plt.title(\"Update Time by Strategy and Format\")\n",
    "plt.xlabel(\"Strategy\")\n",
    "plt.ylabel(\"Update Time (s)\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "id": "query_vis",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Query performance comparison\n",
    "query_df = metrics_df[metrics_df['query_type'].notna()]\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(query_df['query_type'], query_df['query_time_s'], color='seagreen')\n",
    "plt.xticks(rotation=45)\n",
    "plt.title(\"Query Performance Comparison\")\n",
    "plt.xlabel(\"Query Type\")\n",
    "plt.ylabel(\"Query Time (s)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "id": "storage_vis",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Storage cost comparison\n",
    "storage_df = metrics_df.dropna(subset=['storage_size_mb'])\n",
    "storage_summary = storage_df.groupby(['format', 'update_strategy'])['storage_size_mb'].mean().reset_index()\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(storage_summary['format'] + \" \" + storage_summary['update_strategy'], storage_summary['storage_size_mb'], color='orchid')\n",
    "plt.title(\"Storage Size by Target Table\")\n",
    "plt.xlabel(\"Target Table\")\n",
    "plt.ylabel(\"Storage Size (MB)\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "id": "summary_table",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Show all metrics as interactive table\n",
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "display(metrics_df)"
   ]
  },
  {
   "cell_type": "code",
   "id": "complete",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Visualization complete. Review charts above for performance and storage comparisons across ingestion, update, and query activities.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "synapse_pyspark",
   "display_name": "Synapse PySpark"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
